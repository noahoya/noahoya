---
layout: essay
type: essay
title: "The Patterns You Do Not Notice Until You Actually Build Something"
date: 2025-12-04
published: true
labels:
  - IDPM
  - Effort Estimation
  - Project Management
---

When I first saw that we had to estimate effort for every issue, I honestly treated it like a test. Like I was supposed to predict the future and get the numbers right. But once we actually started using estimation and tracking across milestones, I realized it was not about accuracy. It was about being consistent, being truthful, and using the data to manage the project instead of letting the project manage you.

The way I made my effort estimates was simple at first, but it improved as I got more experience. Whenever a new issue went onto the milestone board, I would look at what type of work it involved and compare it to tasks we already did. If it was something repetitive, like building another page with the same layout patterns or reusing components, I estimated lower because the setup work was already solved. If it involved something unfamiliar, like a new library, a database schema change, or complicated UI state, I estimated higher because I knew debugging time was coming. For bigger issues, I also started splitting the work in my head into chunks, like UI, data wiring, validation, testing, and polish. That helped because it reminded me that the work is not just typing code, it is everything around it that makes the feature actually complete.

Even though my estimates were often off, estimating in advance still helped a lot. The biggest benefit was planning the order of work. When the milestone board had a bunch of issues, the estimates made it easier to see which tasks were quick wins and which ones were risky. If something looked like it could block other work, starting it earlier made sense. Estimation also helped me notice scope creep sooner. Some issues started as one simple goal, but once I got into the code, they turned into two or three connected problems. When that happened, the estimate stopped matching reality fast, and that was a signal to split the issue, simplify the approach, or communicate that it was bigger than expected before it became a last minute scramble.

Tracking actual effort was useful because it gave me real data to learn from. After a few issues, I could look back and see how long certain types of work actually took in our codebase, not just how long I thought they would take. That made later estimates more grounded. It also helped explain why progress sometimes felt slow. Even when I was working consistently, time would get eaten by research, planning, debugging, and testing. Seeing that effort recorded made it easier to adjust expectations and make better decisions about how much we could realistically take on for the milestone.

For tracking the actual effort, I timed my work with my phone. When I started working on an issue, I started a timer. When I stopped, I stopped the timer. I did my best not to count breaks, distractions, or time where I was not actually working. For coding effort, I counted time spent writing code, iterating on solutions, debugging, running tests, refactoring, and integrating changes into the codebase. For non coding effort, I also used my phone timer but tracked it separately, counting time spent on requirements analysis, design planning, research, documentation, and communication with teammates. Since I was manually timing, I think my tracking was reasonably accurate, but not perfect. The biggest source of error was context switching, like when I would quickly answer a message or jump between tasks and forget to stop the timer immediately. Even with that, I still trust the data because I was consistent and focused on keeping it honest.

If I had to do this again, there are a few things I would change. First, I would split issues earlier when they contain multiple deliverables. An issue that includes UI, database changes, validation, and tests is basically multiple tasks, and combining them makes both estimating and tracking messy. Second, I would standardize my non coding logging a little more, even if it is just a short note for start time, stop time, and what I did, because that would make the non coding numbers easier to justify later. Third, I would do a mid milestone review where I compare total estimated effort versus total actual effort so far, because that would help adjust scope and priorities earlier instead of learning the lesson at the end.

AI assistance was part of my workflow, and I tried to account for it accurately. I used ChatGPT by OpenAI, model GPT 5.2 Thinking. I mainly used it for breaking issues into subtasks, getting unstuck when I hit an error, and sanity checking approaches. When I used AI during implementation, I counted that time as coding effort because it still involved prompt writing, iterating, reading outputs, verifying correctness, and integrating changes. Representative prompts I used looked like: break this issue into subtasks and estimate minutes, here is an error and the relevant code what should I check, and suggest a clean way to implement a feature while keeping the code readable. The parts I could accept quickly were usually high level checklists, debugging ideas, or small isolated logic. The parts that required edits were anything tied to our specific schema, naming conventions, file structure, or UI behavior. I always had to verify by testing and making sure the solution actually fit our project.

By the end of the project, effort estimation stopped feeling like paperwork and started feeling like a real management skill. The point was never to be perfect. The point was to plan before building, track what actually happened, and use that information to make smarter decisions as the project grows. Honest data beats perfect guesses every time.
